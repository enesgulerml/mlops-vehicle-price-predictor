# ğŸš— End-to-End Used Car Price Prediction (MLOps)

## ğŸ“– Project Overview
This project is a production-grade machine learning application designed to predict used vehicle prices based on various features (brand, year, condition, technical specs). 

Unlike traditional data science notebooks, this project focuses on **MLOps best practices**, featuring a modular architecture, reproducible pipelines, and a clear separation of concerns (Ingestion, Transformation, Training).

## ğŸ—ï¸ Architecture
The project follows a component-based modular structure:

```text
src/
â”œâ”€â”€ components/          # Core Logic Units
â”‚   â”œâ”€â”€ data_ingestion.py      # Splits raw data into Train/Test artifacts
â”‚   â”œâ”€â”€ data_transformation.py # Cleaning, Feature Engineering & Encoding (saves .pkl)
â”‚   â””â”€â”€ model_trainer.py       # Model training (XGBoost/RF) & serialization
â”œâ”€â”€ pipelines/           # Orchestrators (Training & Prediction Pipelines)
â”œâ”€â”€ utils/               # Helpers (Logging, Config management)
â””â”€â”€ ...
```

## ğŸ› ï¸ Tech Stack
* **Language:** Python 3.x
* **Machine Learning:** XGBoost, Scikit-learn, Pandas, NumPy
* **MLOps:** Modular Pipeline Design, Artifact Management, Logging
* **Future Roadmap:** Docker, FastAPI, CI/CD, AWS Deployment

## ğŸš€ Getting Started
### 1. Prerequisites
* Python 3.8+
* Virtual Environment (Recommended)

### 2. Installation
```bash
# Clone the repository
git clone https://github.com/enesgulerml/regression-project.git

# Create and activate virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: .\venv\Scripts\Activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Usage
The pipeline is designed to be triggered component by component (currently):

#### Step 1: Data Ingestion Reads the raw CSV, handles schema, and creates train.csv / test.csv.
```bash
python -m src.components.data_ingestion
```

#### Step 2: Data Transformation Cleans data, handles outliers, performs feature engineering, saves LabelEncoders, and produces .npy arrays.
```bash
python -m src.components.data_transformation
```

#### Step 3: Model Training (Coming Soon) Trains the XGBoost model on processed data.

## ğŸ“ˆ Model Performance
* **Current Model:** XGBoost Regressor
* **Metrics:** Tracking RMSE and R2 Score (Details to be updated after full training).

## ğŸ‘¤ Author
Enes Guler - MLOps Engineer